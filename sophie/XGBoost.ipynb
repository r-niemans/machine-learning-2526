{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed7660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951c188",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973973fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# %%\n",
    "# Import XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "\n",
    "# %%\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5355ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    \"\"\"\n",
    "    Downcasts numeric columns to save memory.\n",
    "    float64 -> float32\n",
    "    int64 -> int32\n",
    "    \"\"\"\n",
    "    print(f\"Original memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    print(f\"New memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca8c9d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395ca4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files: 18\n",
      "Output files: 18\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Check if /kaggle/input exists to determine if running on Kaggle\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    # On Kaggle notebook\n",
    "    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\")\n",
    "else:\n",
    "    # On local PC\n",
    "    DATA_DIR = Path(\"nfl-big-data-bowl-2026-prediction\")\n",
    "    \n",
    "# Load all CSV files from train folder\n",
    "train_input_files = sorted(glob.glob(str(DATA_DIR /'train'/'input_*.csv')))\n",
    "train_output_files = sorted(glob.glob(str(DATA_DIR /'train'/'output_*.csv')))\n",
    "\n",
    "print(f'Input files: {len(train_input_files)}')\n",
    "print(f'Output files: {len(train_output_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8570b",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Combining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86c3bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting train_input...\n",
      "Original memory usage: 2424.32 MB\n",
      "New memory usage: 2145.05 MB\n",
      "Train input shape: (4880579, 23)\n",
      "Train output shape: (562936, 6)\n"
     ]
    }
   ],
   "source": [
    "# Combine data\n",
    "input_dfs = []\n",
    "output_dfs = []\n",
    "\n",
    "for input_file, output_file in zip(train_input_files, train_output_files):\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    output_df = pd.read_csv(output_file)\n",
    "    input_dfs.append(input_df)\n",
    "    output_dfs.append(output_df)\n",
    "\n",
    "train_input = pd.concat(input_dfs, ignore_index=True)\n",
    "train_output = pd.concat(output_dfs, ignore_index=True)\n",
    "print(\"Downcasting train_input...\")\n",
    "train_input = downcast_dtypes(train_input)\n",
    "print(f'Train input shape: {train_input.shape}')\n",
    "print(f'Train output shape: {train_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e94942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input columns:\n",
      "['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y']\n",
      "\n",
      "Output columns:\n",
      "['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']\n",
      "\n",
      "Input sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>play_id</th>\n",
       "      <th>player_to_predict</th>\n",
       "      <th>nfl_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>play_direction</th>\n",
       "      <th>absolute_yardline_number</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>player_role</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>s</th>\n",
       "      <th>a</th>\n",
       "      <th>dir</th>\n",
       "      <th>o</th>\n",
       "      <th>num_frames_output</th>\n",
       "      <th>ball_land_x</th>\n",
       "      <th>ball_land_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>54527</td>\n",
       "      <td>1</td>\n",
       "      <td>right</td>\n",
       "      <td>42</td>\n",
       "      <td>Bryan Cook</td>\n",
       "      <td>6-1</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>Defensive Coverage</td>\n",
       "      <td>52.330002</td>\n",
       "      <td>36.939999</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>322.399994</td>\n",
       "      <td>238.240005</td>\n",
       "      <td>21</td>\n",
       "      <td>63.259998</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>54527</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>42</td>\n",
       "      <td>Bryan Cook</td>\n",
       "      <td>6-1</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>Defensive Coverage</td>\n",
       "      <td>52.330002</td>\n",
       "      <td>36.939999</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>200.889999</td>\n",
       "      <td>236.050003</td>\n",
       "      <td>21</td>\n",
       "      <td>63.259998</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>54527</td>\n",
       "      <td>3</td>\n",
       "      <td>right</td>\n",
       "      <td>42</td>\n",
       "      <td>Bryan Cook</td>\n",
       "      <td>6-1</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>Defensive Coverage</td>\n",
       "      <td>52.330002</td>\n",
       "      <td>36.930000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>147.550003</td>\n",
       "      <td>240.600006</td>\n",
       "      <td>21</td>\n",
       "      <td>63.259998</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>54527</td>\n",
       "      <td>4</td>\n",
       "      <td>right</td>\n",
       "      <td>42</td>\n",
       "      <td>Bryan Cook</td>\n",
       "      <td>6-1</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>Defensive Coverage</td>\n",
       "      <td>52.349998</td>\n",
       "      <td>36.919998</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>131.399994</td>\n",
       "      <td>244.250000</td>\n",
       "      <td>21</td>\n",
       "      <td>63.259998</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>54527</td>\n",
       "      <td>5</td>\n",
       "      <td>right</td>\n",
       "      <td>42</td>\n",
       "      <td>Bryan Cook</td>\n",
       "      <td>6-1</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>Defensive Coverage</td>\n",
       "      <td>52.369999</td>\n",
       "      <td>36.900002</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>123.260002</td>\n",
       "      <td>244.250000</td>\n",
       "      <td>21</td>\n",
       "      <td>63.259998</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  \\\n",
       "0  2023090700      101              False   54527         1          right   \n",
       "1  2023090700      101              False   54527         2          right   \n",
       "2  2023090700      101              False   54527         3          right   \n",
       "3  2023090700      101              False   54527         4          right   \n",
       "4  2023090700      101              False   54527         5          right   \n",
       "\n",
       "   absolute_yardline_number player_name player_height  player_weight  ...  \\\n",
       "0                        42  Bryan Cook           6-1            210  ...   \n",
       "1                        42  Bryan Cook           6-1            210  ...   \n",
       "2                        42  Bryan Cook           6-1            210  ...   \n",
       "3                        42  Bryan Cook           6-1            210  ...   \n",
       "4                        42  Bryan Cook           6-1            210  ...   \n",
       "\n",
       "          player_role          x          y     s     a         dir  \\\n",
       "0  Defensive Coverage  52.330002  36.939999  0.09  0.39  322.399994   \n",
       "1  Defensive Coverage  52.330002  36.939999  0.04  0.61  200.889999   \n",
       "2  Defensive Coverage  52.330002  36.930000  0.12  0.73  147.550003   \n",
       "3  Defensive Coverage  52.349998  36.919998  0.23  0.81  131.399994   \n",
       "4  Defensive Coverage  52.369999  36.900002  0.35  0.82  123.260002   \n",
       "\n",
       "            o  num_frames_output  ball_land_x  ball_land_y  \n",
       "0  238.240005                 21    63.259998        -0.22  \n",
       "1  236.050003                 21    63.259998        -0.22  \n",
       "2  240.600006                 21    63.259998        -0.22  \n",
       "3  244.250000                 21    63.259998        -0.22  \n",
       "4  244.250000                 21    63.259998        -0.22  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>play_id</th>\n",
       "      <th>nfl_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>46137</td>\n",
       "      <td>1</td>\n",
       "      <td>56.22</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>46137</td>\n",
       "      <td>2</td>\n",
       "      <td>56.63</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>46137</td>\n",
       "      <td>3</td>\n",
       "      <td>57.06</td>\n",
       "      <td>16.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>46137</td>\n",
       "      <td>4</td>\n",
       "      <td>57.48</td>\n",
       "      <td>16.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023090700</td>\n",
       "      <td>101</td>\n",
       "      <td>46137</td>\n",
       "      <td>5</td>\n",
       "      <td>57.91</td>\n",
       "      <td>15.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id  play_id  nfl_id  frame_id      x      y\n",
       "0  2023090700      101   46137         1  56.22  17.28\n",
       "1  2023090700      101   46137         2  56.63  16.88\n",
       "2  2023090700      101   46137         3  57.06  16.46\n",
       "3  2023090700      101   46137         4  57.48  16.02\n",
       "4  2023090700      101   46137         5  57.91  15.56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Inspection\n",
    "print(\"Input columns:\")\n",
    "print(train_input.columns.tolist())\n",
    "print(\"\\nOutput columns:\")\n",
    "print(train_output.columns.tolist())\n",
    "print(\"\\nInput sample:\")\n",
    "display(train_input.head())\n",
    "print(\"\\nOutput sample:\")\n",
    "display(train_output.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217656e",
   "metadata": {},
   "source": [
    "# Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2e34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \"\"\"Create comprehensive feature set for optimal prediction\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ball-related features\n",
    "    df['dist_to_ball_land'] = np.sqrt(\n",
    "        (df['x'] - df['ball_land_x'])**2 +\n",
    "        (df['y'] - df['ball_land_y'])**2\n",
    "    )\n",
    "\n",
    "    df['angle_to_ball'] = np.arctan2(\n",
    "        df['ball_land_y'] - df['y'],\n",
    "        df['ball_land_x'] - df['x']\n",
    "    )\n",
    "\n",
    "    df['angle_to_ball_deg'] = np.degrees(df['angle_to_ball'])\n",
    "\n",
    "    df['speed_to_ball'] = df['s'] * np.cos(\n",
    "        np.radians(df['dir']) - df['angle_to_ball']\n",
    "    )\n",
    "\n",
    "    df['delta_x_to_ball'] = df['ball_land_x'] - df['x']\n",
    "    df['delta_y_to_ball'] = df['ball_land_y'] - df['y']\n",
    "    df['manhattan_dist_to_ball'] = np.abs(df['delta_x_to_ball']) + np.abs(df['delta_y_to_ball'])\n",
    "    df['eucl_dist_to_ball'] = np.sqrt((df['ball_land_x'] - df['x'])**2 + (df['ball_land_y'] - df['y'])**2)\n",
    "    df['x_y_dist_ratio'] = np.abs(df['delta_x_to_ball']) / (np.abs(df['delta_y_to_ball']) + 0.1)\n",
    "\n",
    "    # Role encoding\n",
    "    role_map = {\n",
    "        'Targeted Receiver': 4,\n",
    "        'Defensive Coverage': 3,\n",
    "        'Other Route Runner': 2,\n",
    "        'Passer': 1\n",
    "    }\n",
    "    df['role_encoded'] = df['player_role'].map(role_map).fillna(0)\n",
    "\n",
    "    df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n",
    "    df['is_targeted'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "    df['is_defender'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    df['is_passer'] = (df['player_role'] == 'Passer').astype(int)\n",
    "\n",
    "    # Field position\n",
    "    df['field_position'] = df['absolute_yardline_number']\n",
    "    df['play_dir_encoded'] = (df['play_direction'] == 'right').astype(int)\n",
    "\n",
    "    df['dist_from_left_sideline'] = df['y']\n",
    "    df['dist_from_right_sideline'] = 53.3 - df['y']\n",
    "    df['dist_from_nearest_sideline'] = np.minimum(\n",
    "        df['dist_from_left_sideline'],\n",
    "        df['dist_from_right_sideline']\n",
    "    )\n",
    "    df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n",
    "\n",
    "    # Velocity and acceleration components\n",
    "    df['vx'] = df['s'] * np.cos(np.radians(df['dir']))\n",
    "    df['vy'] = df['s'] * np.sin(np.radians(df['dir']))\n",
    "    df['ax'] = df['a'] * np.cos(np.radians(df['dir']))\n",
    "    df['ay'] = df['a'] * np.sin(np.radians(df['dir']))\n",
    "    df['speed_squared'] = df['s'] ** 2\n",
    "    df['accel_squared'] = df['a'] ** 2\n",
    "\n",
    "    # Orientation features\n",
    "    df['orientation_dir_diff'] = np.abs(df['o'] - df['dir'])\n",
    "    df['orientation_dir_diff'] = np.where(\n",
    "        df['orientation_dir_diff'] > 180,\n",
    "        360 - df['orientation_dir_diff'],\n",
    "        df['orientation_dir_diff']\n",
    "    )\n",
    "    df['facing_ball'] = (df['orientation_dir_diff'] < 90).astype(int)\n",
    "\n",
    "    # Physics-based features\n",
    "    df['expected_time_to_ball'] = df['dist_to_ball_land'] / (df['s'] + 0.1)\n",
    "    df['frames_after_ball'] = df['num_frames_output'] - (df['expected_time_to_ball'] * 10)\n",
    "\n",
    "    df['estimated_x_next'] = df['x'] + df['vx'] * 0.1\n",
    "    df['estimated_y_next'] = df['y'] + df['vy'] * 0.1\n",
    "    df['estimated_x_1sec'] = df['x'] + df['vx']\n",
    "    df['estimated_y_1sec'] = df['y'] + df['vy']\n",
    "\n",
    "    df['can_reach_ball'] = (df['expected_time_to_ball'] < df['num_frames_output'] * 0.1).astype(int)\n",
    "\n",
    "    # Kinetic energy proxy\n",
    "    df['kinetic_energy'] = 0.5 * df['speed_squared']\n",
    "\n",
    "    # Trajectory curvature proxy\n",
    "    df['velocity_angle'] = np.arctan2(df['vy'], df['vx'])\n",
    "    df['trajectory_alignment'] = np.abs(df['velocity_angle'] - df['angle_to_ball'])\n",
    "\n",
    "    return df\n",
    "     \n",
    "def add_sequence_features(df, window=3):\n",
    "    \"\"\"Add temporal sequence features\"\"\"\n",
    "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "\n",
    "    # Velocity changes\n",
    "    df['delta_vx'] = df.groupby(['game_id', 'play_id', 'nfl_id'])['vx'].diff()\n",
    "    df['delta_vy'] = df.groupby(['game_id', 'play_id', 'nfl_id'])['vy'].diff()\n",
    "    df['delta_speed'] = df.groupby(['game_id', 'play_id', 'nfl_id'])['s'].diff()\n",
    "\n",
    "    # Acceleration changes (jerk)\n",
    "    df['delta_ax'] = df.groupby(['game_id', 'play_id', 'nfl_id'])['ax'].diff()\n",
    "    df['delta_ay'] = df.groupby(['game_id', 'play_id', 'nfl_id'])['ay'].diff()\n",
    "\n",
    "    # Rolling statistics\n",
    "    for col in ['s', 'a', 'vx', 'vy']:\n",
    "        df[f'{col}_rolling_mean'] = df.groupby(['game_id', 'play_id', 'nfl_id'])[col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'{col}_rolling_std'] = df.groupby(['game_id', 'play_id', 'nfl_id'])[col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = downcast_dtypes(df)\n",
    "\n",
    "    return df\n",
    "     \n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Wrapper function to apply all feature engineering steps\"\"\"\n",
    "    print(\"Creating advanced features...\")\n",
    "    df = create_advanced_features(df)\n",
    "    print(\"Adding sequence features...\")\n",
    "    df = add_sequence_features(df)\n",
    "    print(\"Feature engineering complete.\")\n",
    "    return df\n",
    "\n",
    "def height_to_inches(h):\n",
    "    \"\"\"Converts height string (e.g., '6-1') to inches\"\"\"\n",
    "    try:\n",
    "        f, i = h.split(\"-\")\n",
    "        return int(f) * 12 + int(i)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07106eb5",
   "metadata": {},
   "source": [
    "# Data Processing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf25a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced features...\n",
      "Adding sequence features...\n",
      "Original memory usage: 3317.98 MB\n",
      "New memory usage: 3131.80 MB\n",
      "Feature engineering complete.\n",
      "Filtered (players to predict) shape: (1303440, 74)\n",
      "Merged data shape: (560426, 76)\n",
      "Features shape: (560426, 83)\n",
      "Target shape: (560426, 2)\n",
      "Total features: 83\n"
     ]
    }
   ],
   "source": [
    "# 1. Apply feature engineering to the *entire* input dataset\n",
    "engineered_df = engineer_features(train_input)\n",
    "     \n",
    "# 2. Filter for only the players we need to predict\n",
    "players2predict = engineered_df[engineered_df[\"player_to_predict\"] == True].copy()\n",
    "print(f'Filtered (players to predict) shape: {players2predict.shape}')\n",
    "\n",
    "# 3. Merge with output data to get target variables\n",
    "merged = players2predict.merge(\n",
    "    train_output,\n",
    "    on=[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"],\n",
    "    suffixes=(\"_input\", \"_output\")\n",
    ")\n",
    "print(f'Merged data shape: {merged.shape}')\n",
    "\n",
    "# 4. Apply remaining non-sequential features\n",
    "merged[\"player_height\"] = merged[\"player_height\"].apply(height_to_inches)\n",
    "\n",
    "# 5. --- RE-INTRODUCE ONE-HOT ENCODING ---\n",
    "position_dummies = pd.get_dummies(merged[\"player_position\"], prefix=\"position\")\n",
    "role_dummies = pd.get_dummies(merged[\"player_role\"], prefix=\"role\")\n",
    "merged = pd.concat([\n",
    "    merged,\n",
    "    position_dummies,\n",
    "    role_dummies\n",
    "], axis=1)\n",
    "\n",
    "# 6. Define the final feature columns\n",
    "#    (No longer includes raw categorical columns)\n",
    "feature_cols = [\n",
    "    'absolute_yardline_number', 'player_weight', 'x_input', 'y_input', 's', 'a',\n",
    "    'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y',\n",
    "    'dist_to_ball_land', 'angle_to_ball', 'angle_to_ball_deg',\n",
    "    'speed_to_ball', 'delta_x_to_ball', 'delta_y_to_ball',\n",
    "    'manhattan_dist_to_ball', 'x_y_dist_ratio', 'eucl_dist_to_ball',\n",
    "    'role_encoded',\n",
    "    'is_offense', 'is_targeted', 'is_defender', 'is_passer',\n",
    "    'field_position', 'play_dir_encoded', 'dist_from_left_sideline',\n",
    "    'dist_from_right_sideline', 'dist_from_nearest_sideline',\n",
    "    'dist_from_endzone', 'vx', 'vy', 'ax', 'ay', 'speed_squared',\n",
    "    'accel_squared', 'orientation_dir_diff', 'facing_ball',\n",
    "    'expected_time_to_ball', 'frames_after_ball', 'estimated_x_next',\n",
    "    'estimated_y_next', 'estimated_x_1sec', 'estimated_y_1sec',\n",
    "    'can_reach_ball', 'kinetic_energy', 'velocity_angle',\n",
    "    'trajectory_alignment', 'delta_vx', 'delta_vy', 'delta_speed',\n",
    "    'delta_ax', 'delta_ay', 's_rolling_mean', 's_rolling_std',\n",
    "    'a_rolling_mean', 'a_rolling_std', 'vx_rolling_mean', 'vx_rolling_std',\n",
    "    'vy_rolling_mean', 'vy_rolling_std',\n",
    "    'player_height'\n",
    "]\n",
    "# Add dummy columns to feature list\n",
    "feature_cols.extend([c for c in merged.columns if c.startswith((\"position_\", \"role_\"))])\n",
    "\n",
    "# Save this list for the submission function\n",
    "global final_feature_cols\n",
    "final_feature_cols = feature_cols.copy()\n",
    "\n",
    "\n",
    "# 7. Create final X and y\n",
    "X = merged[final_feature_cols].fillna(0)\n",
    "y = merged[[\"x_output\",\"y_output\"]]\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f\"Total features: {len(final_feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef9172",
   "metadata": {},
   "source": [
    "# Data Split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3edfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 392298\n",
      "Test set size: 168128\n",
      "Target shape: (392298, 2) (samples, [x, y])\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'Target shape: {y_train.shape} (samples, [x, y])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b20194",
   "metadata": {},
   "source": [
    "# Model Training (with XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2b383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training XGBoost models ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38684\\48857711.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmulti_output_booster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 3. Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- Training XGBoost models ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmulti_output_booster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- Training complete ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1362\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params_validated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mrouted_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    279\u001b[0m             delayed(_fit_estimator)(\n\u001b[0;32m    280\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config_and_warning_filters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1982\u001b[0m             \u001b[1;31m# If n_jobs==1, run the computation sequentially and return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1983\u001b[0m             \u001b[1;31m# immediately to avoid overheads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1986\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m         \u001b[1;31m# call is interrupted early and that the same instance is immediately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1924\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1925\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_running\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1926\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1928\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarning_filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1336\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m             \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEvalsLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m             train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[0;32m   1341\u001b[0m                 \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[0mway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \"\"\"\n\u001b[0;32m    700\u001b[0m     \u001b[1;31m# Feature_types contains the optional reference categories from the booster object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[0;32m    702\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                 return QuantileDMatrix(\n\u001b[0;32m   1255\u001b[0m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_bin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_bin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[1;34m\"If data iterator is used as input, data like label should be \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m                     \u001b[1;34m\"specified as batch argument.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1744\u001b[1;33m         self._init(\n\u001b[0m\u001b[0;32m   1745\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m             \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[0mnext_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1807\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1808\u001b[1;33m         \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1809\u001b[0m         \u001b[1;31m# delay check_call to throw intermediate exception first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1810\u001b[0m         \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1811\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[1;31m#  pylint 2.7.0 believes `self._exception` can be None even with `assert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[1;31m#  isinstace`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mexc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m  \u001b[1;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;31m# On dask, the worker is restarted and somehow the information is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;31m# lost.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdft_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mit\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mit\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0minput_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temporary_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m                 new, feature_names, feature_types = _proxy_transform(\n\u001b[0m\u001b[0;32m    642\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                     \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                     \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m   1681\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_pa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m         df, feature_names, feature_types = _transform_pandas_df(\n\u001b[0m\u001b[0;32m   1686\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[0;32m    662\u001b[0m     feature_names, feature_types = pandas_feature_info(\n\u001b[0;32m    663\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas_transform_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m     return (\n\u001b[0;32m    668\u001b[0m         \u001b[0mPandasTransformed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_categories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_is_np_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_np_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moth_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;31m# FIXME(jiamingy): Investigate the possibility of using dataframe protocol or arrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;31m# IPC format for pandas so that we can apply the data transformation inside XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(ser)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moth_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"PdSeries\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;31m# The dtypes module is added in 1.25.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         npdtypes = np_dtypes and isinstance(\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             (\n\u001b[0;32m    568\u001b[0m                 \u001b[1;31m# pylint: disable=no-member\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloat32DType\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\misak\\anaconda3\\envs\\APPY2025\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6317\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6318\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6319\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6320\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6321\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the XGBoost Regressor\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,                     # Use all cores\n",
    "    tree_method='hist',            # Use fast histogram-based method\n",
    "    enable_categorical=False       # We are using OHE, not internal support\n",
    ")\n",
    "\n",
    "# 2. Wrap the XGBoost model with MultiOutputRegressor\n",
    "multi_output_booster = MultiOutputRegressor(estimator=xgb_model)\n",
    "\n",
    "# 3. Fit the model\n",
    "print(\"--- Training XGBoost models ---\")\n",
    "multi_output_booster.fit(X_train, y_train)\n",
    "print(\"--- Training complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14b884",
   "metadata": {},
   "source": [
    "# Model Evaluation : Assessing Test and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Predict on training and test data\n",
    "y_hat_train = multi_output_booster.predict(X_train)\n",
    "y_hat_test = multi_output_booster.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "\n",
    "print(f\"Training Mean Squared Error (MSE): {train_mse}\")\n",
    "print(f\"Test Mean Squared Error (MSE): {test_mse}\")\n",
    "\n",
    "# You can also calculate MSE per output (x and y)\n",
    "train_mse_x = mean_squared_error(y_train.iloc[:, 0], y_hat_train[:, 0])\n",
    "train_mse_y = mean_squared_error(y_train.iloc[:, 1], y_hat_train[:, 1])\n",
    "test_mse_x = mean_squared_error(y_test.iloc[:, 0], y_hat_test[:, 0])\n",
    "test_mse_y = mean_squared_error(y_test.iloc[:, 1], y_hat_test[:, 1])\n",
    "\n",
    "print(f\"\\nTest MSE for X: {test_mse_x}\")\n",
    "print(f\"Test MSE for Y: {test_mse_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69c217",
   "metadata": {},
   "source": [
    "# Importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the feature importances from each fitted model inside the wrapper\n",
    "all_importances = [\n",
    "    estimator.feature_importances_ for estimator in multi_output_booster.estimators_\n",
    "]\n",
    "\n",
    "# 2. Average the importances across all models\n",
    "# axis=0 calculates the mean down each column\n",
    "average_importances = np.mean(all_importances, axis=0)\n",
    "\n",
    "# 3. Create the DataFrame using the averaged importances\n",
    "feature_names = X_train.columns.tolist()\n",
    "feature_imp = pd.DataFrame(\n",
    "    {'importance': average_importances},\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "# 4. Sort and display the results\n",
    "print(feature_imp.sort_values(by='importance', ascending=False).head(20))\n",
    "\n",
    "# %%\n",
    "y_hat_boost = multi_output_booster.predict(X_test)\n",
    "\n",
    "mse = np.mean((y_test.values - y_hat_boost)**2) # Use .values for numpy compatibility\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465d5f0",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fe7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports and API setup ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Add the evaluation API to the system path\n",
    "# (Uses the DATA_DIR variable you defined in your \"Data Loading\" cell)\n",
    "EVAL_DIR = DATA_DIR / 'kaggle_evaluation'\n",
    "if str(EVAL_DIR) not in sys.path:\n",
    "    sys.path.append(str(EVAL_DIR))\n",
    "\n",
    "# Now these imports will work\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "\n",
    "# --- Prediction Function ---\n",
    "\n",
    "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates predictions for the test set.\n",
    "    This function is called by the evaluation API and must return a\n",
    "    DataFrame in the submission format.\n",
    "    \n",
    "    It uses the globally trained 'multi_output_booster', 'final_feature_cols',\n",
    "    and the feature engineering functions.\n",
    "    \"\"\"\n",
    "    print(\"API: Received prediction request...\")\n",
    "    \n",
    "    # --- Convert Polars to Pandas ---\n",
    "    test_input_df = test_input.to_pandas()\n",
    "    test_df = test.to_pandas()\n",
    "    \n",
    "    # --- Helper Function (must be defined or available) ---\n",
    "    def height_to_inches(h):\n",
    "        try:\n",
    "            f, i = h.split(\"-\")\n",
    "            return int(f) * 12 + int(i)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # 1. Feature Engineering (must match training data)\n",
    "    print(\"API: Performing full feature engineering...\")\n",
    "    engineered_df = engineer_features(test_input_df)\n",
    "    \n",
    "    # 2. Filter for only the players we need to predict\n",
    "    players2predict = engineered_df[engineered_df[\"player_to_predict\"] == True].copy()\n",
    "    \n",
    "    # 3. Apply post-merge/filtering features\n",
    "    print(\"API: Applying secondary features...\")\n",
    "    players2predict['player_height'] = players2predict['player_height'].apply(height_to_inches)\n",
    "    \n",
    "    # 4. --- ONE-HOT ENCODING ---\n",
    "    print(\"API: Applying One-Hot Encoding...\")\n",
    "    test_position_dummies = pd.get_dummies(players2predict['player_position'], prefix='position')\n",
    "    test_role_dummies = pd.get_dummies(players2predict['player_role'], prefix='role')\n",
    "    \n",
    "    # 5. Concatenate final features\n",
    "    test_features = pd.concat([players2predict, test_position_dummies, test_role_dummies], axis=1)\n",
    "\n",
    "    # 6. Feature selection and alignment\n",
    "    #    (Relies on 'final_feature_cols' from training being in global scope)\n",
    "    print(\"API: Aligning feature columns...\")\n",
    "    if 'x_input' not in test_features.columns:\n",
    "        test_features = test_features.rename(columns={'x': 'x_input', 'y': 'y_input'})\n",
    "        \n",
    "    # Use reindex to align columns perfectly with training data\n",
    "    # This adds missing dummy columns (and fills with 0)\n",
    "    # and drops any new/unexpected columns\n",
    "    X_test_api = test_features.reindex(columns=final_feature_cols, fill_value=0)\n",
    "    \n",
    "    # 7. Handle all other missing values\n",
    "    X_test_api = X_test_api.fillna(0)\n",
    "\n",
    "    print(f'API: Test features shape: {X_test_api.shape}')\n",
    "\n",
    "    # 8. Predict on test data\n",
    "    print('API: Predicting test data...')\n",
    "    # Uses the globally trained 'multi_output_booster'\n",
    "    test_predictions = multi_output_booster.predict(X_test_api)\n",
    "    test_pred_x = test_predictions[:, 0]\n",
    "    test_pred_y = test_predictions[:, 1]\n",
    "    \n",
    "    # Add predictions back to the filtered dataframe\n",
    "    players2predict['pred_x'] = test_pred_x\n",
    "    players2predict['pred_y'] = test_pred_y\n",
    "    \n",
    "    # 9. Format the submission\n",
    "    submission = test_df.copy()\n",
    "    submission['id'] = submission['game_id'].astype(str) + '_' + \\\n",
    "                       submission['play_id'].astype(str) + '_' + \\\n",
    "                       submission['nfl_id'].astype(str) + '_' + \\\n",
    "                       submission['frame_id'].astype(str)\n",
    "                       \n",
    "    # Merge predictions\n",
    "    test_pred_df = players2predict[['game_id', 'play_id', 'nfl_id', 'frame_id', 'pred_x', 'pred_y']].copy()\n",
    "    \n",
    "    submission = submission.merge(\n",
    "        test_pred_df,\n",
    "        on=['game_id', 'play_id', 'nfl_id', 'frame_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 10. Return only 'x' and 'y' columns\n",
    "    predictions_df = submission[['pred_x', 'pred_y']].rename(columns={'pred_x': 'x', 'pred_y': 'y'})\n",
    "    \n",
    "    # Fill missing values with 0 (for any rows in test_df we couldn't predict)\n",
    "    predictions_df = predictions_df.fillna(0)\n",
    "    \n",
    "    print(\"API: Prediction request complete.\")\n",
    "    \n",
    "    # Check assertions\n",
    "    assert isinstance(predictions_df, (pd.DataFrame, pl.DataFrame))\n",
    "    assert len(predictions_df) == len(test_df)\n",
    "    \n",
    "    # Return the DataFrame with *only* x and y\n",
    "    return predictions_df\n",
    "\n",
    "# --- Server Setup ---\n",
    "# This code sets up and runs the server\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"Starting server for competition reruns...\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # This runs the local gateway for testing\n",
    "    print(\"Running local gateway for testing...\")\n",
    "    inference_server.run_local_gateway((f'{DATA_DIR}',)) # Pass the DATA_DIR as the path\n",
    "\n",
    "print(\"Submission process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APPY2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
